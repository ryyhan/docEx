# VLM API Configuration (for vlm_mode=api)
VLM_API_PROVIDER=openai  # Options: openai, groq, anthropic, google, azure, custom
VLM_API_KEY=your-api-key-here
# VLM_API_BASE_URL=  # Optional: for custom endpoints or Azure (e.g., https://your-resource.openai.azure.com/openai/deployments/your-deployment)

# Legacy (deprecated - use VLM_API_KEY instead)
# OPENAI_API_KEY=sk-your-openai-api-key

# VLM Prompt Customization
# Set to "default" to use the built-in optimized prompt.
# Or provide your own text here.
VLM_PROMPT=default

# Storage Directory for extracted files
STORAGE_DIR=./results
